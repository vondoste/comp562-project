{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQFXs1jkcMtILkO1308FK+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UfIoMR2cSVVX"},"outputs":[],"source":["import numpy as np\n","from typing import Callable,DefaultDict\n","from gensim.models.ldamodel import LdaModel\n","from operator import itemgetter\n","from sklearn.cluster import KMeans\n","\n","Cluster = list[np.ndarray]\n","ClusterMetric = Callable[[list[Cluster]],float|list[float]] #inputs list of clusters, outputs value per cluster\n","\n","def CH(clusters:list[Cluster])->float:\n","  assert isinstance(clusters,list) and isinstance(clusters[0],list) and isinstance(clusters[0][0],np.ndarray)\n","  n_clusters = len(clusters)\n","  Wk:float = 0\n","  centers = [np.average(clust,axis=0) for clust in clusters];\n","  full_center = np.average([v for c in clusters for v in c],axis=0)\n","  for cluster,center in zip(clusters,centers):\n","    for x in cluster:\n","      Wk += np.sum((center - x)**2)\n","\n","  Bk:float = 0\n","  for cluster,center in zip(clusters,centers):\n","    Bk += len(cluster)*(np.sum((center-full_center)**2))\n","\n","  return Bk/Wk * (sum(map(len,clusters))-n_clusters)/(n_clusters - 1)\n","\n","def SC(clusters:list[Cluster])->list[float]:\n","  assert isinstance(clusters,list) and isinstance(clusters[0],list) and isinstance(clusters[0][0],np.ndarray)\n","  n_clusters = len(clusters)\n","  centers = [np.average(clust,axis=0) for clust in clusters];\n","  res = [];\n","  for cluster,center in zip(clusters,centers):\n","    nearest = clusters[np.argmin(np.linalg.norm(center-centers,axis=1))]\n","    sc_k = 0\n","    for v in cluster:\n","      a = np.sum(np.linalg.norm(v-cluster,axis=1))/(len(cluster)-1) #don't ask about the math. a is average distance within a cluster\n","      b = np.sum(np.linalg.norm(v-nearest,axis=1))/(len(cluster))\n","      sc_k += (b-a)/(max(b,a))/len(cluster)\n","    res.append(sc_k)\n","  return res\n","\n","BagOfWords = list[tuple[int,float]]\n","BagsOfWords = list[list[tuple[int,float]]]\n","def vecsToBows(vecs:list[np.ndarray])->BagsOfWords:\n","  bow:BagsOfWords = []\n","  for vec in vecs:\n","    b = []\n","    for i in np.nonzero(vec)[0]:\n","      b.append((i,vec[i]));\n","    bow.append(b)\n","  return bow\n","\n","def bowsToVecs(bow:BagsOfWords,n_words:int)->list[np.ndarray]:\n","  res = []\n","  for doc in bow:\n","    vec = np.zeros((n_words));\n","    for word,count in doc:\n","      vec[word] = count\n","    res.append(vec)\n","  return res\n","\n","def do_LDA(bag_of_words:BagsOfWords,\n","           num_topics:int|None=None,\n","           cluster_metrics:dict[str,ClusterMetric]={\"CH\":CH,\"SC\":SC}\n","           )->tuple[list[Cluster],dict[str,float|list[float]]]:\n","  assert isinstance(bag_of_words,list) and isinstance(bag_of_words[0],list) and isinstance(bag_of_words[0][0],tuple) #type STRONG\n","  if num_topics:\n","    model = LdaModel(bag_of_words,passes=4,iterations=200)\n","  else:\n","    model = LdaModel(bag_of_words,passes=4,iterations=200)\n","\n","  topic_dict:dict[int,BagsOfWords] = DefaultDict(list)\n","  for doc in bag_of_words:\n","    topics:list[tuple[int,float]] = model[doc] #topic probability distribution\n","    topic:int = max(topics,key=itemgetter(1))[0]\n","    topic_dict[topic].append(doc)\n","\n","  clusters:list[Cluster] = []\n","  veclength:int = np.max([v[0] for vs in topic_dict.values() for vi in vs for v in vi])+1;\n","  vlenth = model.num_topics\n","  for topic,bow in topic_dict.items():\n","    clusters.append(bowsToVecs(bow,veclength));\n","\n","  metrics:dict[str,float|list[float]] = {name:metric(clusters) for name,metric in cluster_metrics.items()}\n","  return clusters,metrics\n","\n","def do_kmeans(vectors:list[np.ndarray],\n","              num_means:int=8,\n","              cluster_metrics:dict[str,ClusterMetric]={\"CH\":CH,\"SC\":SC}\n","              )->tuple[list[Cluster],dict[str,float|list[float]]]:\n","  assert isinstance(vectors,list) and isinstance(vectors[0],np.ndarray)\n","  model = KMeans(num_means);\n","  labels = model.fit_predict(vectors);\n","\n","  clusters:list[Cluster] = []\n","  for id in np.unique(labels):\n","    clusters.append([vectors[i] for i in np.argwhere(labels == id)[0]])\n","\n","  metrics:dict[str,float|list[float]] = {name:metric(clusters) for name,metric in cluster_metrics.items()}\n","  return clusters,metrics"]}]}